{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inżynieria lingwistyczna\n",
    "Ten notebook jest oceniany półautomatycznie. Nie twórz ani nie usuwaj komórek - struktura notebooka musi zostać zachowana. Odpowiedź wypełnij tam gdzie jest na to wskazane miejsce - odpowiedzi w innych miejscach nie będą sprawdzane (nie są widoczne dla sprawdzającego w systemie).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie domowe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 - eksploracja przestrzeni zagnieżdżeń\n",
    "Wczytajmy do przestrzeni plik zagnieżdżeń, który należy pobrać ze strony:\n",
    "https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.pl.vec Są to zagnieżdzenia dla języka polskiego uzyskane systemem fastText.\n",
    "\n",
    "Do przestrzeni wczytujemy tylko 100 tys. najczęstrzych słów, tak aby operacje przebiegały szybciej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff72904e199199567cefa7ecc512bc5b",
     "grade": false,
     "grade_id": "cell-a4ed145fec4874e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "def load_vectors(fname, limit = 100000):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    n = min(n,limit)\n",
    "    embeddings = np.empty((n,d), dtype = np.float)\n",
    "    words_idx = []\n",
    "    for i, line in enumerate(fin):\n",
    "        if i >= limit:\n",
    "            break\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        words_idx.append(tokens[0])\n",
    "        embeddings[i] =  np.array(tokens[1:]).astype(np.float)\n",
    "    return words_idx, embeddings\n",
    "words_idx, embeddings = load_vectors('wiki.pl.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższe zadania mają na celu poekserymentowanie z przestrzenią zagnieżdżeń, ale też zrozumienie stojącymi za nich operacji. Dozwolone jest korzystanie tylko z podstawowych operatorów Python i numpy (w szczególności zakaz dotyczy: sklearn, gensim, fasttext itd.)\n",
    "\n",
    "Jeśli potrzebujesz do dalszego przetwarzania przeprowadzenia jakichś normalizacji macierzy -- możesz wstępnie przetworzyć macierz zagnieżdzeń poniżej. Pamiętaj, że sprawdzarka będzie używała wywołań do `embeddings` (i `words_idx`) -- musisz nadpisać macierz zagnieżdzeń. To pole jest pomocnicze i nie podlega ocenie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bad4efac5cfe3b895e04c7d1d616878c",
     "grade": false,
     "grade_id": "cell-6fee4cb7a7fea5c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# ******** Enable it only if not downloaded wiki.pl.vec yet ********\n",
    "#!wget -q -O wiki.pl.vec https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.pl.vec\n",
    "\n",
    "# This will map words into indexes to speed up search index\n",
    "words_idx = dict([(word, index) for index, word in enumerate(words_idx)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementuj funkcję, która obliczy podobieństwo kosinusowe pomiędzy dwoma wyrazami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89e46295053248c56d68caf5a00e3a81",
     "grade": false,
     "grade_id": "cell-433776f5de68cf95",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_sim(word_a, word_b, words_idx, embeddings):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two words with using embeddings and words idx lists.\n",
    "    Known issues: If not found word - throw exception\n",
    "    \"\"\"\n",
    "    # Get from embeddings vector assigned to word A\n",
    "    a = embeddings[words_idx[word_a]]\n",
    "    \n",
    "    # Get from embeddings vector assigned to word B\n",
    "    b = embeddings[words_idx[word_b]]\n",
    "    \n",
    "    # Cosine similarity\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a0436c8372e1c2bc61b92bd05a6c765",
     "grade": true,
     "grade_id": "cell-890341bd1cbcc5d2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_almost_equal\n",
    "assert_almost_equal(calc_sim(\"bieber\", \"rihanna\", words_idx, embeddings), calc_sim(\"rihanna\", \"bieber\", words_idx, embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policz podobieństwo pomiędzy wyrazem `bieber` a wyrazami:\n",
    "    - `rihanna`\n",
    "    - `piłsudski`\n",
    "    - `kanada`\n",
    "    - `polska`\n",
    "    - `piosenka`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.524583248263655"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_sim('bieber', 'rihanna', words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d0c5da4e71a95a4f3aacba9f9b4b664",
     "grade": false,
     "grade_id": "cell-3333712301dd0bbe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.524583248263655\n",
      "0.1930395805146356\n",
      "0.20042742126487934\n",
      "0.12505934735679372\n",
      "0.2874871368858332\n"
     ]
    }
   ],
   "source": [
    "print(calc_sim('bieber', 'rihanna', words_idx, embeddings))\n",
    "print(calc_sim('bieber', 'piłsudski', words_idx, embeddings))\n",
    "print(calc_sim('bieber', 'kanada', words_idx, embeddings))\n",
    "print(calc_sim('bieber', 'polska', words_idx, embeddings))\n",
    "print(calc_sim('bieber', 'piosenka', words_idx, embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementuj funkcję, która zwróci najbardziej podobne słowa (miara kosinusowa) do danego słowa `word`. W wyniku wypisz tylko `top` słów z najbliższymi zagnieżdżeniami, pomijając słowo `word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d174e9429ec96be4232e58eb4683ffb8",
     "grade": false,
     "grade_id": "cell-e8417832104ee5eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Used itemgetter to speed-up sorting elements in list\n",
    "from operator import itemgetter\n",
    "\n",
    "def find_similar(word, words_idx, embedding_matrix, top=10):\n",
    "    \"\"\"\n",
    "    Build similarity list between `word` and each word.\n",
    "    Select `top` number of elements and return it.\n",
    "    Ignore `word` on this list\n",
    "    \"\"\"\n",
    "    # Calculate similarity between `word` and each element in dictionary\n",
    "    similarity = [(calc_sim(word, w, words_idx, embedding_matrix), w) for w in words_idx.keys() if w != word]\n",
    "    \n",
    "    # Order by similarity - highest value at first\n",
    "    similarity = sorted(similarity, key=itemgetter(0), reverse=True)\n",
    "    \n",
    "    # Return `top` number of similar words\n",
    "    return [w for (sim, w) in similarity[0:top]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff37028a810bf8da732cfdb41cc309b7",
     "grade": true,
     "grade_id": "cell-84f4627b3ebe0906",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "assert len(find_similar(\"radość\", words_idx, embeddings)) == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znajdź najbardziej podobne słowa do kobieta, politechnika, mateusz, szczecin, niemcy, piłsudski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kobietą',\n",
       " 'dziewczyna',\n",
       " 'mężczyzna',\n",
       " 'kobietę',\n",
       " 'dziewczynka',\n",
       " 'mężczyznę',\n",
       " 'staruszka',\n",
       " 'mężczyzną',\n",
       " 'kobiecie',\n",
       " 'mężczyzny']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar('kobieta', words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00f26fb5c5ebdbd5a5dd006c892c9aba",
     "grade": false,
     "grade_id": "cell-9e2eaa4a951e17b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kobietą', 'dziewczyna', 'mężczyzna', 'kobietę', 'dziewczynka', 'mężczyznę', 'staruszka', 'mężczyzną', 'kobiecie', 'mężczyzny']\n",
      "['politechniki', 'politechniką', 'politechnikę', 'politechniczny', 'politechnice', 'politechnicznej', 'politechnicznego', 'politechnicznym', 'inżynierska', 'elektrotechnika']\n",
      "['łukasz', 'bartłomiej', 'bartosz', 'kacper', 'marcin', 'mateusza', 'tomasz', 'patryk', 'rafał', 'mateuszem']\n",
      "['szczecinek', 'szczeciński', 'szczecinem', 'gryfino', 'szczecinie', 'stargard', 'szczecina', 'koszalin', 'szczecińska', 'świnoujście']\n",
      "['niemieccy', 'naziści', 'alianci', 'okupanci', 'polacy', 'hitlerowcy', 'niemieckie', 'rosjanie', 'niemców', 'niemcom']\n",
      "['piłsudskim', 'piłsudskiego', 'piłsudskiemu', 'sosnkowski', 'mościcki', 'śmigły', 'józef', 'żeligowski', 'piłsudczyków', 'sosnkowskiego']\n"
     ]
    }
   ],
   "source": [
    "print(find_similar('kobieta', words_idx, embeddings))\n",
    "print(find_similar('politechnika', words_idx, embeddings))\n",
    "print(find_similar('mateusz', words_idx, embeddings))\n",
    "print(find_similar('szczecin', words_idx, embeddings))\n",
    "print(find_similar('niemcy', words_idx, embeddings))\n",
    "print(find_similar('piłsudski', words_idx, embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krótko skomentuj wyniki dla słowa `niemcy`. Które z powstałych analogii biorą się z semantycznego powiązania a które z semantycznego podobieństwa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c31c2929dc80543bebea431c05decbfd",
     "grade": true,
     "grade_id": "cell-f09fc185fd252182",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Komentarz:  Część otrzymanych analogii pochodzi z nawiązania do II WŚ i ataku hitlerowskich Niemiec na Polskę.\n",
    "#             Mamy także analogie z semantycznego podobieństwa.\n",
    "# Semantycznie powiązane: 'alianci', 'polacy', 'rosjanie', 'naziści', 'okupanci', 'hitlerowcy'\n",
    "# Semantyczne podobieństwo: 'niemieccy', 'niemieckie', 'niemców', 'niemcom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementuj funkcje szukającą brakującego elementu relacji ,,`word_a` jest do `word_a2` jak `word_b` jest do...''. Funkcja powinna zwrócić 10 najbardziej pasujących słow z pominięciem słów będących jej argumentami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e6e16dac4cb376f4d53a9d755cd46dc",
     "grade": false,
     "grade_id": "cell-63d29c3e720be966",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_pair(word_a, word_a2, word_b, words_idx, matrix, top=10):\n",
    "    \"\"\"\n",
    "    Find similar pair - missing `wordB*` in `wordA` is similar to `wordA*` like `wordB` to `wordB*`\n",
    "    \"\"\"\n",
    "    # Not allowed words\n",
    "    not_allowed_words = set([word_a, word_a2, word_b])\n",
    "    \n",
    "    # Calculate similarity based on formula from lecture\n",
    "    similarity = [(calc_sim(w, word_b, words_idx, matrix) - calc_sim(w, word_a, words_idx, matrix) + calc_sim(w, word_a2, words_idx, matrix), w) for w in words_idx.keys() if w not in not_allowed_words]\n",
    "    \n",
    "    # Sort similarity - first element with highest value\n",
    "    similarity = sorted(similarity, key=itemgetter(0), reverse=True)\n",
    "    \n",
    "    # Return `top` number of similar words\n",
    "    return [w for (sim, w) in similarity[0:top]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7663a43e711a8e860bbc06d41b6ca904",
     "grade": true,
     "grade_id": "cell-0d5187c215c3d03c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "assert find_similar_pair( \"mężczyzna\", \"król\", \"kobieta\", words_idx, embeddings)[0] == \"królowa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pieniądze są do profesora jak wiedza do..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96e68dff29fccbb7ee7cb889aeaaf45c",
     "grade": false,
     "grade_id": "cell-8f5621bb8ded7490",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'habilitowany'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_pair('pieniądze', 'profesor', 'wiedza', words_idx, embeddings, top=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mateusza jest do mateusz jak łukasza do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89ccdc6a4c7685a211811f0c6d5e796e",
     "grade": false,
     "grade_id": "cell-3215c64840cc460e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'łukasz'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_pair('mateusza', 'mateusz', 'łukasza', words_idx, embeddings, top=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warszawa jest do \"polska\" jak \"berlin\" do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2831d8f28423fd701364d67e72570994",
     "grade": false,
     "grade_id": "cell-8e4d868c692f267a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'niemiecka'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_pair('warszawa', 'polska', 'berlin', words_idx, embeddings, top=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zurich jest do ETH jak Poznań do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['„poznań',\n",
       " 'wrocław',\n",
       " 'poznania',\n",
       " 'poznańskie',\n",
       " 'gniezno',\n",
       " 'kraków',\n",
       " 'poznaniu',\n",
       " 'uam',\n",
       " 'wielkopolski',\n",
       " 'poznańską']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_pair( \"zurich\", \"eth\", \"poznań\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niemcy są do Merkel jak Polska do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kaczyńska',\n",
       " 'ekonomistka',\n",
       " 'lewandowska',\n",
       " 'kwaśniewska',\n",
       " 'lekarka',\n",
       " 'parlamentarzystka',\n",
       " 'marcinkiewicz',\n",
       " 'nowacka',\n",
       " 'dziennikarka',\n",
       " 'olszewska']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_pair( \"niemcy\", \"merkel\", \"polska\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na wektorach możemy wykonywać standardowe operacje algebry liniowej takie jak np. projekcja czyli rzutowanie danych na jakichś zbiór osi (więcej: notatki z algebry liniowej np. https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/least-squares-determinants-and-eigenvalues/projections-onto-subspaces/). W szczególności może to się przydać do zrzutowania słowa na przestrzeń w której pewny wybrany kierunek (wskazywany przez wektor) jest eliminowany.\n",
    "\n",
    "Do czego może to się przydać? Jeśli uruchomisz funkcję `find_similar` dla słowa ,,mateusza'' znajdziesz m.in. ,,łukasza'' ale także ,,ewangelia'', ,,ewangelisty'' i ,,apostoła''. Chcąc pominąc kontekst religijny tego słowa możesz zrzutować jego reprezentacje na przestrzeń bez wektora ,,ewangelia'' i poszukać jego najbliższych sąsiadów (którymi będą teraz po prostu imiona męskie). Zaimplementuj taką funkcję.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c635c05e6782ad6ef07a5ac3346f65c9",
     "grade": false,
     "grade_id": "cell-9c73750e7d423c6a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardowe poszukiwanie: ['łukasza', 'ewangelii', 'ewangelisty', 'ewangelia', 'bartłomieja', 'ewangeliach', 'apostoła', 'mateusz', 'tymoteusza', 'jakuba']\n",
      "Poszukiwanie po projekcji: ['macieja', 'andrzeja', 'antoniego', 'stanisława', 'marcina', 'michała', 'kacpra', 'bartłomieja', 'rafała', 'sebastiana']\n"
     ]
    }
   ],
   "source": [
    "def find_similar_with_rejection(word, remove, words_idx, matrix, top=10):\n",
    "    \"\"\"\n",
    "    Działanie analogiczne do find_similar z dodatkowym parametrem remove, \n",
    "    który jest *listą* słów, które należy wyrzucić poprzez projekcję.\n",
    "    Dla remove=[] powinno się zwracać dokładnie to samo co find_similar\n",
    "    \"\"\"\n",
    "    if len(remove) == 0:\n",
    "        updated_matrix = matrix\n",
    "    else:\n",
    "        # Copy to be able to modify matrix\n",
    "        updated_matrix = matrix.copy()\n",
    "        word_index = words_idx[word]\n",
    "        \n",
    "        # Remove not alloved vectors\n",
    "        for removed_word in remove:\n",
    "            updated_matrix[word_index] = updated_matrix[word_index] - updated_matrix[words_idx[removed_word]]\n",
    "        \n",
    "    # Calculate like in normal `find similar`\n",
    "    return find_similar(word, words_idx, updated_matrix, top)\n",
    "    \n",
    "print('Standardowe poszukiwanie:', find_similar_with_rejection('mateusza', [] , words_idx, embeddings))\n",
    "print('Poszukiwanie po projekcji:', find_similar_with_rejection('mateusza', ['ewangelia'] , words_idx, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cf5c44bd1df54c1da4106b8830dd322",
     "grade": true,
     "grade_id": "cell-b647aedbe8f9db7b",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "assert \"ewangelii\" in find_similar_with_rejection(\"mateusza\",[] , words_idx, embeddings)\n",
    "assert \"ewangelii\" not in find_similar_with_rejection(\"mateusza\",[\"ewangelia\"] , words_idx, embeddings)\n",
    "assert \"ewangelisty\" not in find_similar_with_rejection(\"mateusza\",[\"ewangelia\"] , words_idx, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogicznie słowo ,,java'' jest nie tylko nazwą języka programownia (https://pl.wikipedia.org/wiki/Java_(ujednoznacznienie)) -- jest np. nazwą geograficzną (indonezyjska wyspa koło Sumatry). Sprawdź jakie wyrazy są podobne do \"java\" oraz po odrzuceniu kierunku \"javascript\" (tj. kierunku związanego z językami programowania)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e732ddade5feede63d07547766bcf949",
     "grade": false,
     "grade_id": "cell-d9d015bfeb8e25f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['javascript', 'javy', 'c#', 'c++', 'programowania', 'implementacja', 'lisp', 'framework', 'api', 'programistyczne']\n",
      "['tromp', 'sumatra', 'niszczycielami', 'indonezja', 'penang', 'fregatą', 'jawa', 'lion', 'krążowniki', 'niszczyciele']\n"
     ]
    }
   ],
   "source": [
    "print(find_similar_with_rejection('java', [], words_idx, embeddings))\n",
    "print(find_similar_with_rejection('java', ['javascript'], words_idx, embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbuj poekseprymentować samemu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a88f0a6d0571a66b40d04bc9cb8e65a",
     "grade": false,
     "grade_id": "cell-673e06a42de6bc26",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inżynierię', 'inżynierii', 'biotechnologia', 'inżynierskie', 'inżynierska', 'miksowanie', 'informatyka', 'technologia', 'inżynier', 'elektronika']\n",
      "['miksowanie', 'klawiszowe', 'perkusja', 'basowa', 'inżynierię', 'mastering', 'gitara', 'perkusyjne', 'inżynier', 'instrumenty']\n",
      "['lingwistyki', 'językoznawstwo', 'lingwistyczne', 'filologia', 'fonetyka', 'semantyka', 'antropologia', 'językoznawstwie', 'kulturoznawstwo', 'lingwista']\n",
      "['symulacja', 'wizualizacja', 'korekcja', 'mistyka', 'bianka', 'bariera', 'iluzja', 'symulacji', 'izolacja', 'percepcja']\n"
     ]
    }
   ],
   "source": [
    "print(find_similar_with_rejection('inżynieria', [], words_idx, embeddings))\n",
    "print(find_similar_with_rejection('inżynieria', ['technologia'], words_idx, embeddings))\n",
    "\n",
    "print(find_similar_with_rejection('lingwistyka', [], words_idx, embeddings))\n",
    "print(find_similar_with_rejection('lingwistyka', ['językoznawstwo'], words_idx, embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonanie projekcji w przestrzeni zagnieżdżeń może być jedną z prostych technik zwalczenia tzw. gender bias (http://wordbias.umiacs.umd.edu/) w reprezentacji słów. Okazuje się, że wykonanie projekcji macierzy zagnieżdżeń na przestrzeń w której ,,brakuje kierunku he-she'' może być bardzo prostą techniką zredukowania tego typu obciążenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 - zagnieżdżenia dokumentów\n",
    "W tym ćwiczeniu powócimy do zbioru tweetów, który analizowaliśmy w poprzednim dokumencie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data set ['tweets.txt']\n"
     ]
    }
   ],
   "source": [
    "from helpers import DataSet\n",
    "training_set = DataSet(['tweets.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dear @Microsoft the newOoffice for Mac is great and all, but no Lync update? C'mon.\n",
      "['dear', '@microsoft', 'the', 'newooffice', 'for', 'mac', 'is', 'great', 'and', 'all', ',', 'but', 'no', 'lync', 'update', '?', \"c'mon\", '.']\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "for i in training_set.tweets:\n",
    "    print(i.text)\n",
    "    print(i.tokens)\n",
    "    print(i.clazz)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tym razem do zbudowania reprezentacji będziemy używać narzędzie Universal Sentence Encoder stworzone przez Googla na bazie głębokiej sieci uśredniającej (i architektur rekurencyjnych). Poniższy kod pokazuje sposób użycia tego narzędzia. \n",
    "Kod spokojnie można wywoływać na CPU -- choć ściąganie modelu trochę może potrwać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.03133018 -0.06338634 -0.01607502 ... -0.03242778 -0.04575741\n",
      "   0.05370456]\n",
      " [ 0.05080861 -0.01652428  0.01573781 ...  0.00976659  0.03170123\n",
      "   0.0178812 ]], shape=(2, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ***** DOWNLOAD Universal Sentence Encoder ONCE *****\n",
    "# !wget -q -O universal-sentence-encoder-4.tar.gz https://tfhub.dev/google/universal-sentence-encoder/4?tf-hub-format=compressed\n",
    "# !tar -xzf universal-sentence-encoder-4.tar.gz\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embed = hub.load('universal-sentence-encoder-4')\n",
    "use_embeddings = embed([\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"I am a sentence for which I would like to get its embedding\"])\n",
    "print (use_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystując reprezetnację USE wytrenuj wybrany klasyfikator z pakietu `sklearn` i zweryfikuj jego jakość działania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ec9460c36ab328559c89319de53da65",
     "grade": false,
     "grade_id": "cell-26c33314c55313ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6542124542124542"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split test and train dataset\n",
    "X = list(embed([tweet.text for tweet in training_set.tweets]))\n",
    "y = [tweet.clazz for tweet in training_set.tweets]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=127228)\n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "# Fit classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check prediction score\n",
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skomentuj wyniki i odnieś je do wyników z poprzedniego zadania domowego. Na ile użycie reprezentacji rozproszonych pozwoliło na poprawę wyników?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "635819ecfcec9e909b5f4b2261ea14a5",
     "grade": true,
     "grade_id": "cell-e08f7b8feff88383",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Wyniki:\n",
    "# * FeatureHasher - 0.5296703296703297\n",
    "# * Bag of clusters - 0.5882783882783883\n",
    "# * Universal Sentence Encoder - 0.6542124542124542\n",
    "# \n",
    "# Dzięki wykorzystaniu USE udało się poprawić wyniki.\n",
    "# Wykorzystuje on embeddingi do wyrażenia sentencji w postaci reprezentacji wektorowej.\n",
    "# Najbardziej jest to widoczne w odniesieniu do bazowej wersji z Feature Hasherem, gdzie obserujemy poprawę o 13 pkt procentowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3 - konstruowanie zagnieżdżeń\n",
    "W tym ćwiczeniu kontynuujemy pracę z tweetami, ale pomijamy całkowicie ich klasy. Zbiór tweetów potraktujemy jako korpus do nauczenia zagnieżdżeń słów przy pomocy macierzy PMI.\n",
    "- Wypełnij macierz kontekst - dokument przy użyciu symetrycznego okna o promieniu 4 (po 4 słowa w każdą stronę)\n",
    "- Możesz ograniczyć słownictwo do 10K słów\n",
    "- Przekształć macierz w macierz PPMI\n",
    "- Stwórz zagnieżdżenia wykorzystując dekompozycję SVD do wybranej wymiarowości $d$ (ze względu na koszt obliczeniowy może to być mała wymiarowość np. $d=10$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d780996410f05351b8dc57e50531c78d",
     "grade": true,
     "grade_id": "cell-dc2433e668962e28",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from math import log2\n",
    "from numpy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def hyperspace_analogue_to_language(tweets, r=4):\n",
    "    # Key - `word`, Values - dict with `another_word` => `count`\n",
    "    # Only 20k words allowed - this is only for educational purposes - no extra security check here\n",
    "    matrix = np.zeros((20_000, 20_000))\n",
    "    word_to_index = dict()\n",
    "    last_index = 0\n",
    "\n",
    "    for tweet in training_set.tweets:\n",
    "        # Prepare generator with weight assigned to each position in window\n",
    "        weights = [0, *list(range(r, 0, -1))]\n",
    "    \n",
    "        sentence = tweet.tokens\n",
    "        for index, center_word in enumerate(sentence):\n",
    "            # Get rowId assigned to word\n",
    "            rowId = word_to_index.get(center_word, None)\n",
    "            \n",
    "            # If not found word in dictionary - set new index\n",
    "            if rowId is None:\n",
    "                rowId = last_index\n",
    "                word_to_index[center_word] = last_index\n",
    "                last_index += 1\n",
    "\n",
    "            # Iterate over elements in window and combined weights\n",
    "            window = iter(sentence[max(index - r, 0):index + r + 1])\n",
    "            for word, weight in zip(window, weights):\n",
    "                # If not found word in dictionary - set new index\n",
    "                wordId = word_to_index.get(word, None)\n",
    "                if wordId is None:\n",
    "                    wordId = last_index\n",
    "                    word_to_index[word] = last_index\n",
    "                    last_index += 1\n",
    "                    \n",
    "                # Update value in matrix\n",
    "                matrix[rowId, wordId] += weight\n",
    "\n",
    "            # If index < window size - add at beggining of weights list new weight\n",
    "            if index < r:\n",
    "                weights.insert(0, r - index)\n",
    "    \n",
    "    return matrix[:last_index, :last_index], word_to_index\n",
    "\n",
    "def transform_into_ppmi_matrix(matrix):\n",
    "    (rows, columns) = matrix.shape\n",
    "    \n",
    "    # PPMI matrix\n",
    "    ppmi_matrix = matrix.copy()\n",
    "    \n",
    "    # Calculate sum of values in matrix\n",
    "    total_values = np.sum(ppmi_matrix)\n",
    "    \n",
    "    # Calculate probability of elements in each row\n",
    "    row_values = np.sum(ppmi_matrix, axis=1)\n",
    "    row_values = row_values / total_values\n",
    "    \n",
    "    # Calculate probability of elements in each column\n",
    "    column_values = np.sum(ppmi_matrix, axis=0)\n",
    "    column_values = column_values / total_values\n",
    "    \n",
    "    # Make PPMI matrix as probability matrix with P(w, c) as value\n",
    "    ppmi_matrix = ppmi_matrix / total_values\n",
    "    \n",
    "    # Calculate PPMI values\n",
    "    for rowId in range(0, rows):\n",
    "        for colId in range(0, columns):\n",
    "            denominator = row_values[rowId] * column_values[colId]\n",
    "            if denominator == 0:\n",
    "                ppmi_matrix[rowId, colId] = 0\n",
    "            else:\n",
    "                # Calculate PMI value\n",
    "                pmi_value = ppmi_matrix[rowId, colId] / denominator\n",
    "\n",
    "                # Calculate log2 only if not equal 0\n",
    "                if pmi_value != 0:\n",
    "                    pmi_value = log2(pmi_value)\n",
    "\n",
    "                ppmi_matrix[rowId, colId] = max(0, pmi_value)\n",
    "            \n",
    "    return ppmi_matrix\n",
    "    \n",
    "def pmi_matrix_svd_decomposition(matrix, d=10):\n",
    "    svd_obj = TruncatedSVD(n_components=d)\n",
    "    return svd_obj.fit_transform(matrix)\n",
    "\n",
    "hal_matrix, words_to_index_dict = hyperspace_analogue_to_language(training_set.tweets)\n",
    "ppmi_matrix = transform_into_ppmi_matrix(hal_matrix)\n",
    "svd_matrix = pmi_matrix_svd_decomposition(ppmi_matrix, d=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestuj działanie Twoich zagnieżdżeń wykorzystując funkcję `find_similar` na wybranych słowach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccb11abbddd43b64c364aea20584f1dd",
     "grade": true,
     "grade_id": "cell-f6fa13a67093698a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mobile', 'pc', 'education', 'gaming', 'publishers', 'access', '6-inch', 'waterproof', 'tablet', '@gabeaul']\n",
      "['loans', '25000', 'yano', 'doom', 'apologist', '#parttimeproblems', 'tomo-', '#cant', 'insight2015', 'gloom']\n",
      "['trending', '#shopinsidermorning', 'js', 'dallas', 'rally', 'wwe', 'area~', 'charity', 'appeared', 'indoors']\n",
      "['of', 'in', 'is', '1st', 'for', 'on', 'a', \"'s\", 'thrones', 'sunday']\n"
     ]
    }
   ],
   "source": [
    "print(find_similar('microsoft', words_to_index_dict, svd_matrix))\n",
    "print(find_similar('bug', words_to_index_dict, svd_matrix))\n",
    "print(find_similar('topic', words_to_index_dict, svd_matrix))\n",
    "print(find_similar('the', words_to_index_dict, svd_matrix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
